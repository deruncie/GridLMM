% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/GridLMMnet.R
\name{GridLMMnet}
\alias{GridLMMnet}
\title{LASSO solutions in a linear mixed model using GridLMM}
\usage{
GridLMMnet(formula, data, X, weights = NULL, centerX = TRUE,
  scaleX = TRUE, relmat = NULL, h2_divisions = 10, h2_start = NULL,
  alpha = 1, nlambda = 100, lambda.min.ratio = ifelse(nobs < nvars, 0.01,
  1e-04), lambda = NULL, RE_setup = NULL, V_list_setup = NULL,
  save_V_list = NULL, diagonalize = T, svd_K = T, drop0_tol = 1e-10,
  mc.cores = parallel::detectCores(), clusterType = "mclapply",
  verbose = T, ...)
}
\arguments{
\item{formula}{A two-sided linear formula as used in \code{\link[lme4]{lmer}} describing the fixed-effects
and random-effects of the model on the RHS and the response on the LHS. Note: correlated random-effects
are not implemented, so using one or two vertical bars (\code{|}) or one is identical. At least one random effect is needed.}

\item{data}{A data frame containing the variables named in \code{formula}.}

\item{X}{Variables in model that well be penalized with the elastic net penalty. Covariates specified in \code{formula} are not penalized.}

\item{weights}{An optional vector of observation-specific weights.}

\item{centerX}{TRUE/FALSE for each. Applied to the \code{X} matrix before using \code{X} to form any GRMs.}

\item{scaleX}{TRUE/FALSE for each. Applied to the \code{X} matrix before using \code{X} to form any GRMs.}

\item{relmat}{A list of matrices that are proportional to the (within) covariance structures of the group level effects. 
The names of the matrices should correspond to the columns in \code{data} that are used as grouping factors. All levels
of the grouping factor should appear as rownames of the corresponding matrix.}

\item{h2_divisions}{Number of divisions of each variance component on grid}

\item{h2_start}{Optional. Matrix with each row a vector of \eqn{h^2} parameters defining starting values for the grid. Typically ML/REML solutions for the null model. 
If null, will be calculated using \link{GridLMM_ML}.}

\item{alpha}{The elasticnet mixing parameter, with
    \eqn{0\le\alpha\le 1}. The penalty is defined
    as \deqn{(1-\alpha)/2||\beta||_2^2+\alpha||\beta||_1.} \code{alpha=1}
    is the lasso penalty, and \code{alpha=0} the ridge penalty.}

\item{nlambda}{The number of \code{lambda} values - default is 100.}

\item{lambda.min.ratio}{Smallest value for \code{lambda}, as a fraction of
    \code{lambda.max}, the (data derived) entry value (i.e. the smallest
  value for which all coefficients are zero). The default depends on the
  sample size \code{nobs} relative to the number of variables
  \code{nvars}. If \code{nobs > nvars}, the default is \code{0.0001},
  close to zero.  If \code{nobs < nvars}, the default is \code{0.01}.
  A very small value of
  \code{lambda.min.ratio} will lead to a saturated fit in the \code{nobs <
  nvars} case. This is undefined for
  \code{"binomial"} and \code{"multinomial"} models, and \code{glmnet}
  will exit gracefully when the percentage deviance explained is almost
  1.}

\item{lambda}{A user supplied \code{lambda} sequence. Typical usage
    is to have the 
    program compute its own \code{lambda} sequence based on
    \code{nlambda} and \code{lambda.min.ratio}. Supplying a value of
    \code{lambda} overrides this. WARNING: use with care. Avoid supplying
  a single value for \code{lambda} (for predictions after CV use \code{predict()}
  instead).  Supply instead
    a decreasing sequence of \code{lambda} values. \code{glmnet} relies
  on its warms starts for speed, and its often faster to fit a whole
  path than compute a single fit.}

\item{RE_setup}{Object containing variables for setting up error model with random effects. Can be re-passed to the function to re-run the same model.}

\item{V_list_setup}{Object containing variables for setting up error model with random effects. Can be re-passed to the function to re-run the same model.}

\item{diagonalize}{If TRUE and the model includes only a single random effect, the "GEMMA" trick will be used to diagonalize V. This is done
by calculating the SVD of K, which can be slow for large samples.}

\item{svd_K}{If TRUE and \code{nrow(K) < nrow(Z)}, then the SVD is done on \eqn{K} instead of \eqn{ZKZ^T}}

\item{drop0_tol}{Values closer to zero than this will be set to zero when forming sparse matrices.}

\item{mc.cores}{Number of cores to use for parallel evaluations.}

\item{clusterType}{`mclapply`}

\item{verbose}{Should progress be printed to the screen?}

\item{...}{}
}
\value{
An object with S3 class "glmnet","*" , where "*" is "elnet". See \code{\link[glmnet]{glmnet}}.
}
\description{
Finds LASSO or Elastic Net solutions for a multiple regression problem with correlated errors.
}
\details{
Finds the full LASSO or Elastic Net solution path by running \code{\link[glmnet]{glmnet}} at each grid vertex.
}
